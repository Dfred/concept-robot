Abstract:
=========

This software is part of the CONCEPT project from the University of Plymouth.

This part consists of modules for cognition. It allows for running a camera with face tracking, which submits relevant
movements to the expression server controlling a robot head. Optionally this can be controlled by voice commands. 
Furthermore, it allows for the simulation of concept learning through language game interaction between a teaching 
and a learning agent.

More information can be found at http://www.tech.plym.ac.uk/SoCCE/CONCEPT/


Requirements:
=============

For main modules:
	- python 2.7
	- numpy 1.3.0
	- OpenCV 2.1
	- pyvision 0.9.0 (http://sourceforge.net/projects/pyvision/)
		- including pylab
	
For voice commands:
	- Julius 4.1.4 (http://julius.sourceforge.jp/en_index.php)
	- julius-voxforge 0.1.1 (acoustic models for Julius English)
	
For visualisation:
	- Gnuplot 4
	- gnuplot-py 1.8 (http://sourceforge.net/projects/gnuplot-py/)
	
	
	
To run:
=======

Open a console/terminal and 'cd' to the directory containing this file.

- without voice commands, type './start.sh'
- using voice commands, type './start.sh voice'

You can specify server and port for both adding extra arguments in the form server_address:server_port (eg: 192.168.1.1:31337 )
