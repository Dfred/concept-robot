

Abstract:
=========

This software is part of the CONCEPT project from the University of Plymouth, under supervision of Dr Tony Belpaeme.

This part holds modules for cognition. It allows for running a camera with face tracking, which submits relevant
movements to the expression server controlling a robot head. Optionally this can be controlled by voice commands. 
Furthermore, it allows for the simulation of concept learning through language game interaction between a teaching 
and a learning agent.

More information can be found at http://www.tech.plym.ac.uk/SoCCE/CONCEPT/


Requirements:
=============

For main modules:
	- python 2.6
	- numpy 1.3.0
	- OpenCV 2.1
	- pyvision 0.9.0 (http://sourceforge.net/projects/pyvision/)
		- including pylab
	
	
For voice commands:
	- Julius 4.1.4 (http://julius.sourceforge.jp/en_index.php)
	- julius-voxforge 0.1.1 (acoustic models for Julius English)
	
For visualisation:
	- Gnuplot 4
	- gnuplot-py 1.8 (http://sourceforge.net/projects/gnuplot-py/)
	
	
	
To run:
=======

- to run using voice commands, type 'python main.py' in a console.
- to run using voice commands, type 'julius -quiet -input mic -C julian.jconf 2>/dev/null | ./voice_command.py' in a console.

