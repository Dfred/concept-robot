Abstract:
=========

This software is part of the CONCEPT project from the University of Plymouth, under supervision of Dr tony Belpaeme.

The team involves :
- frederic Delaunay, human-robot interaction
- joachim De Greeff, conceptual modeling

The project is part of frederic Delaunay's PhD, under supervision of Dr tony Belpaeme.
This PhD is expected to end in late 2011.
In the meantime, you are welcomed to try the software and submit bugfixes.

More information at http://www.tech.plym.ac.uk/SoCCE/CONCEPT/



Requirements (In this order):
=============

- python 2.6
- blender 2.49b
- for Windows, readline (if you want to use the readline client, http://newcenturycomputers.net/projects/download.cgi/Readline-1.7.win32-py2.6.exe)

Running the software:
=====================

Windows:
-------
YOU HAVE TO CUSTOMIZE start.bat to match YOUR OWN path.
Try to achieve step 3) for open people (target file is in HRI/face/blender/)
Then run start.bat


Open people would just:
----------------------

1) Open a shell and change into the directory containing this file.
2) you can load environment variables (supposedly for development):

$ source ./env.sh

3) open the blend file to generate a standalone version for your platform:

$ edit_face

Use blender menu: File > Save Game as Runtime, and save it as: "lightHead"

4) now start the facial animation system with:
 
$ ./face.sh

Now you can connect and start setting Action Units according to the protocol definition.


Contact: frederic.delaunay@plymouth.ac.uk
========
